{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "def load_pretrained_model():\n",
    "    \"\"\"Load a pretrained ResNet-50 model in evaluation mode.\"\"\"\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess the image: resize, crop, normalize, and convert to tensor.\"\"\"\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = preprocess(image).unsqueeze(0).requires_grad_(True)\n",
    "    return image, input_tensor\n",
    "\n",
    "def get_prediction(model, input_tensor):\n",
    "    \"\"\"Perform forward pass and return the predicted class index.\"\"\"\n",
    "    output = model(input_tensor)\n",
    "    predicted_class = output.argmax().item()\n",
    "    return output, predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = load_pretrained_model()\n",
    "    image_path = \"Ressources/panda.jpg\"\n",
    "    image, input_tensor = preprocess_image(image_path)\n",
    "    output, predicted_class = get_prediction(model, input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nasta\\miniconda3\\envs\\adaexam\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nasta\\miniconda3\\envs\\adaexam\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_layers = 0\n",
    "conv_layers = []\n",
    "\n",
    "model_children = list(model.children())\n",
    "\n",
    "def extract_conv_layers(model):\n",
    "    global no_of_layers\n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            no_of_layers += 1\n",
    "            conv_layers.append(layer)\n",
    "        elif isinstance(layer, nn.Sequential) or isinstance(layer, nn.Module):\n",
    "            extract_conv_layers(layer)\n",
    "\n",
    "extract_conv_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nomber of layers:  53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"nomber of layers: \", no_of_layers)\n",
    "conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess the image: resize, crop, normalize, and convert to tensor.\"\"\"\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = preprocess(Image.open(image_path).convert(\"RGB\")).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "image_path = \"Ressources/panda.jpg\"\n",
    "image = preprocess_image(image_path)\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 4 skipped due to shape mismatch: Given groups=1, weight of size [256, 64, 1, 1], expected input[1, 256, 112, 112] to have 64 channels, but got 256 channels instead\n",
      "Layer 14 skipped due to shape mismatch: Given groups=1, weight of size [512, 256, 1, 1], expected input[1, 512, 56, 56] to have 256 channels, but got 512 channels instead\n",
      "Layer 27 skipped due to shape mismatch: Given groups=1, weight of size [1024, 512, 1, 1], expected input[1, 1024, 28, 28] to have 512 channels, but got 1024 channels instead\n",
      "Layer 46 skipped due to shape mismatch: Given groups=1, weight of size [2048, 1024, 1, 1], expected input[1, 2048, 14, 14] to have 1024 channels, but got 2048 channels instead\n",
      "Layer 0: torch.Size([1, 3, 224, 224])\n",
      "Layer 1: torch.Size([1, 64, 112, 112])\n",
      "Layer 2: torch.Size([1, 64, 112, 112])\n",
      "Layer 3: torch.Size([1, 64, 112, 112])\n",
      "Layer 4: torch.Size([1, 256, 112, 112])\n",
      "Layer 5: torch.Size([1, 256, 112, 112])\n",
      "Layer 6: torch.Size([1, 64, 112, 112])\n",
      "Layer 7: torch.Size([1, 64, 112, 112])\n",
      "Layer 8: torch.Size([1, 256, 112, 112])\n",
      "Layer 9: torch.Size([1, 64, 112, 112])\n",
      "Layer 10: torch.Size([1, 64, 112, 112])\n",
      "Layer 11: torch.Size([1, 256, 112, 112])\n",
      "Layer 12: torch.Size([1, 128, 112, 112])\n",
      "Layer 13: torch.Size([1, 128, 56, 56])\n",
      "Layer 14: torch.Size([1, 512, 56, 56])\n",
      "Layer 15: torch.Size([1, 512, 56, 56])\n",
      "Layer 16: torch.Size([1, 128, 56, 56])\n",
      "Layer 17: torch.Size([1, 128, 56, 56])\n",
      "Layer 18: torch.Size([1, 512, 56, 56])\n",
      "Layer 19: torch.Size([1, 128, 56, 56])\n",
      "Layer 20: torch.Size([1, 128, 56, 56])\n",
      "Layer 21: torch.Size([1, 512, 56, 56])\n",
      "Layer 22: torch.Size([1, 128, 56, 56])\n",
      "Layer 23: torch.Size([1, 128, 56, 56])\n",
      "Layer 24: torch.Size([1, 512, 56, 56])\n",
      "Layer 25: torch.Size([1, 256, 56, 56])\n",
      "Layer 26: torch.Size([1, 256, 28, 28])\n",
      "Layer 27: torch.Size([1, 1024, 28, 28])\n",
      "Layer 28: torch.Size([1, 1024, 28, 28])\n",
      "Layer 29: torch.Size([1, 256, 28, 28])\n",
      "Layer 30: torch.Size([1, 256, 28, 28])\n",
      "Layer 31: torch.Size([1, 1024, 28, 28])\n",
      "Layer 32: torch.Size([1, 256, 28, 28])\n",
      "Layer 33: torch.Size([1, 256, 28, 28])\n",
      "Layer 34: torch.Size([1, 1024, 28, 28])\n",
      "Layer 35: torch.Size([1, 256, 28, 28])\n",
      "Layer 36: torch.Size([1, 256, 28, 28])\n",
      "Layer 37: torch.Size([1, 1024, 28, 28])\n",
      "Layer 38: torch.Size([1, 256, 28, 28])\n",
      "Layer 39: torch.Size([1, 256, 28, 28])\n",
      "Layer 40: torch.Size([1, 1024, 28, 28])\n",
      "Layer 41: torch.Size([1, 256, 28, 28])\n",
      "Layer 42: torch.Size([1, 256, 28, 28])\n",
      "Layer 43: torch.Size([1, 1024, 28, 28])\n",
      "Layer 44: torch.Size([1, 512, 28, 28])\n",
      "Layer 45: torch.Size([1, 512, 14, 14])\n",
      "Layer 46: torch.Size([1, 2048, 14, 14])\n",
      "Layer 47: torch.Size([1, 2048, 14, 14])\n",
      "Layer 48: torch.Size([1, 512, 14, 14])\n",
      "Layer 49: torch.Size([1, 512, 14, 14])\n",
      "Layer 50: torch.Size([1, 2048, 14, 14])\n",
      "Layer 51: torch.Size([1, 512, 14, 14])\n",
      "Layer 52: torch.Size([1, 512, 14, 14])\n",
      "Layer 53: torch.Size([1, 2048, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "results = [image]\n",
    "current_input = image  \n",
    "\n",
    "for i in range(no_of_layers):\n",
    "    try:\n",
    "        new_input = conv_layers[i](current_input)\n",
    "        current_input = new_input\n",
    "        results.append(current_input)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Layer {i} skipped due to shape mismatch: {e}\")\n",
    "        new_input = new_input + current_input\n",
    "        #continue # skips when there is skip connection\n",
    "        current_input = new_input\n",
    "        results.append(current_input)\n",
    "\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"Layer {i}: {res.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for num_layer in range(len(results)):\n",
    "    plt.figure(figsize=(16, 16))\n",
    "\n",
    "    layer_viz = results[num_layer].squeeze()\n",
    "    print(f\"Layer {num_layer + 1}: {layer_viz.shape}\")\n",
    "\n",
    "    num_filters = layer_viz.shape[0]\n",
    "    grid_size = math.ceil(math.sqrt(num_filters))\n",
    "\n",
    "    for i, feature_map in enumerate(layer_viz):\n",
    "        plt.subplot(grid_size, grid_size, i + 1)\n",
    "        plt.imshow(feature_map.detach().cpu().numpy())\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaexam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
